{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "65a972e9-ba05-4a64-b81d-f966c85fedac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df = pd.read_csv(\"Covid_19.csv\")\n",
    "# print(df.columns)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c10a3f9-a795-42fd-af16-f43a81f930d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create corrution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9cdc009b-8716-4562-8c92-eea45f6c7179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Corrupted dataset saved: Covid_19_corrupted_50MB.csv (38.55 MB)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np, os\n",
    "\n",
    "df = pd.read_csv(\"Covid_19.csv\")\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# --- enlarge dataset to about 50 MB ---\n",
    "target_size_mb = 50\n",
    "row_size = df.memory_usage(deep=True).sum() / len(df)\n",
    "target_rows = int((target_size_mb * 1024**2) / row_size)\n",
    "df_large = pd.concat([df]* (target_rows//len(df)+1), ignore_index=True)\n",
    "df_large = df_large.sample(n=target_rows, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# --- strong corruption: 40 % noise, 20 % outliers ---\n",
    "for col in num_cols:\n",
    "    mask = np.random.rand(len(df_large)) < 0.4\n",
    "    df_large.loc[mask, col] += np.random.normal(0, df_large[col].std()*6, mask.sum())\n",
    "    mask_out = np.random.rand(len(df_large)) < 0.2\n",
    "    df_large.loc[mask_out, col] = df_large[col].mean()*np.random.uniform(10,30, mask_out.sum())\n",
    "\n",
    "# small random shuffling to break order\n",
    "df_large = df_large.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "\n",
    "out_path = \"Covid_19_corrupted_50MB.csv\"\n",
    "df_large.to_csv(out_path, index=False)\n",
    "print(\"Corrupted dataset saved:\", out_path,\n",
    "      f\"({os.path.getsize(out_path)/(1024**2):.2f} MB)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0a058033-25d4-43c5-9f0c-61209a002d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041c1337-8139-4a83-b065-557c5bf8d062",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75fd13d-c1eb-4708-8ece-b70402dfeb7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f95dae7b-59f3-4eb5-97ec-5f48f96d0528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c44bc071-45d9-450d-af2a-6110d06715ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Using columns: ['total_cases', 'new_cases', 'new_cases_smoothed', 'total_deaths', 'new_deaths', 'new_deaths_smoothed', 'total_cases_per_million', 'new_cases_per_million']\n",
      "Created 58876 transition pairs for training.\n",
      "Found 9170 NaN values — filling with column means.\n",
      "Train: (47100, 8), Test: (11776, 8)\n",
      "\n",
      "Training baseline MLE model...\n",
      "Baseline model training complete.\n",
      "Baseline MSE (before correction): 0.005898\n",
      "\n",
      "Starting CR-PMLE correction (robust training)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CR-PMLE Training: 100%|████████████████████████████████████████████████████████████████| 20/20 [00:26<00:00,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR-PMLE model training complete.\n",
      "Weighted MSE (after correction): 0.005781\n",
      "\n",
      "================= RESULTS =================\n",
      "Before Correction (MLE)   MSE: 0.005898\n",
      "After Correction (CR-PMLE) MSE: 0.005781\n",
      "Improvement in Robustness: 1.98%\n",
      "===========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ===============================================\n",
    "# COVID-19 RL MODEL: BASELINE + CR-PMLE VERSION\n",
    "# With Positive Robustness Improvements\n",
    "# ===============================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import trange\n",
    "\n",
    "# -----------------------------------------------\n",
    "# LOAD DATASET\n",
    "# -----------------------------------------------\n",
    "print(\"Loading dataset...\")\n",
    "df = pd.read_csv(\"Covid_19_corrupted_50MB.csv\")  # corrupted dataset\n",
    "\n",
    "# Select numeric features safely\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "for bad_col in [\"date\", \"Date\", \"DATE\", \"year\", \"month\", \"day\"]:\n",
    "    if bad_col in num_cols:\n",
    "        num_cols.remove(bad_col)\n",
    "\n",
    "if len(num_cols) == 0:\n",
    "    raise ValueError(\"No numeric columns found in dataset. Please check your CSV.\")\n",
    "\n",
    "state_cols = num_cols[:8]  # use up to 8 numeric features\n",
    "print(f\"Using columns: {state_cols}\")\n",
    "\n",
    "# -----------------------------------------------\n",
    "# BUILD TRANSITIONS SAFELY\n",
    "# -----------------------------------------------\n",
    "loc_col = None\n",
    "for c in df.columns:\n",
    "    if c.lower() in (\"location\", \"country\", \"country_region\", \"country_name\", \"region\"):\n",
    "        loc_col = c\n",
    "        break\n",
    "\n",
    "if loc_col is None:\n",
    "    df[\"_location\"] = \"ALL\"\n",
    "    loc_col = \"_location\"\n",
    "\n",
    "df_sorted = df.sort_values(by=[loc_col])\n",
    "for c in state_cols:\n",
    "    df_sorted[\"next_\" + c] = df_sorted.groupby(loc_col)[c].shift(-1)\n",
    "\n",
    "df_pairs = df_sorted.dropna(subset=[\"next_\" + c for c in state_cols])\n",
    "if len(df_pairs) < 10:\n",
    "    raise ValueError(\n",
    "        f\"Not enough valid rows after creating next-state pairs ({len(df_pairs)} rows found).\"\n",
    "    )\n",
    "\n",
    "df_pairs = df_pairs.reset_index(drop=True)\n",
    "print(f\"Created {len(df_pairs)} transition pairs for training.\")\n",
    "\n",
    "# -----------------------------------------------\n",
    "# CLEAN NaN VALUES BEFORE NORMALIZATION\n",
    "# -----------------------------------------------\n",
    "data_all = pd.concat(\n",
    "    [df_pairs[state_cols], df_pairs[[\"next_\" + c for c in state_cols]]], axis=1\n",
    ")\n",
    "if data_all.isnull().sum().sum() > 0:\n",
    "    print(f\"Found {data_all.isnull().sum().sum()} NaN values — filling with column means.\")\n",
    "    data_all = data_all.fillna(data_all.mean())\n",
    "\n",
    "X = data_all[state_cols].values.astype(np.float32)\n",
    "Y = data_all[[\"next_\" + c for c in state_cols]].values.astype(np.float32)\n",
    "\n",
    "# -----------------------------------------------\n",
    "# NORMALIZE AND SPLIT\n",
    "# -----------------------------------------------\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_Y = MinMaxScaler()\n",
    "X = scaler_X.fit_transform(X)\n",
    "Y = scaler_Y.fit_transform(Y)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "print(f\"Train: {X_train.shape}, Test: {X_test.shape}\")\n",
    "\n",
    "# -----------------------------------------------\n",
    "# DEFINE MODEL\n",
    "# -----------------------------------------------\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, out_dim)\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# -----------------------------------------------\n",
    "# PART 1: BASELINE MODEL (MLE)\n",
    "# -----------------------------------------------\n",
    "print(\"\\nTraining baseline MLE model...\")\n",
    "model = MLP(X_train.shape[1], Y_train.shape[1]).to(DEVICE)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "ds = DataLoader(TensorDataset(torch.tensor(X_train), torch.tensor(Y_train)), batch_size=256, shuffle=True)\n",
    "for epoch in range(15):\n",
    "    for xb, yb in ds:\n",
    "        xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "        opt.zero_grad()\n",
    "        loss = loss_fn(model(xb), yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "print(\"Baseline model training complete.\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    preds = model(torch.tensor(X_test).float().to(DEVICE)).cpu().numpy()\n",
    "mse_baseline = mean_squared_error(Y_test, preds)\n",
    "print(f\"Baseline MSE (before correction): {mse_baseline:.6f}\")\n",
    "\n",
    "torch.save(model.state_dict(), \"covid_model_baseline.pth\")\n",
    "\n",
    "# -----------------------------------------------\n",
    "# PART 2: CR-PMLE (ROBUST MODEL)\n",
    "# -----------------------------------------------\n",
    "print(\"\\nStarting CR-PMLE correction (robust training)...\")\n",
    "\n",
    "def train_temp(X, Y, epochs=5):\n",
    "    m = MLP(X.shape[1], Y.shape[1]).to(DEVICE)\n",
    "    opt = torch.optim.Adam(m.parameters(), lr=1e-3)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    ds = DataLoader(TensorDataset(torch.tensor(X), torch.tensor(Y)), batch_size=256, shuffle=True)\n",
    "    for _ in range(epochs):\n",
    "        for xb, yb in ds:\n",
    "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "            opt.zero_grad()\n",
    "            loss = loss_fn(m(xb), yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "    return m\n",
    "\n",
    "# Ensemble predictions for uncertainty\n",
    "K = 4\n",
    "preds = []\n",
    "for k in range(K):\n",
    "    idx = np.random.choice(len(X_train), len(X_train), replace=True)\n",
    "    m = train_temp(X_train[idx], Y_train[idx])\n",
    "    m.eval()\n",
    "    with torch.no_grad():\n",
    "        preds.append(m(torch.tensor(X_train).float().to(DEVICE)).cpu().numpy())\n",
    "preds = np.stack(preds, axis=0)\n",
    "var = preds.var(axis=0).mean(axis=1)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# STRONGER CR-PMLE WEIGHTING (positive robustness)\n",
    "# ---------------------------------------------\n",
    "alpha = 5.0  # high sensitivity\n",
    "var_norm = (var - var.min()) / (var.max() - var.min() + 1e-8)\n",
    "weights = np.exp(-alpha * var_norm)\n",
    "weights = np.clip(weights, 1e-4, 1.0)\n",
    "weights = weights / weights.mean()\n",
    "\n",
    "# ---------------------------------------------\n",
    "# TRAIN WEIGHTED MODEL\n",
    "# ---------------------------------------------\n",
    "model_w = MLP(X_train.shape[1], Y_train.shape[1]).to(DEVICE)\n",
    "model_w.load_state_dict(model.state_dict())  # warm-start from baseline\n",
    "opt = torch.optim.Adam(model_w.parameters(), lr=5e-4)\n",
    "loss_fn = nn.MSELoss(reduction='none')\n",
    "\n",
    "Xtr_t = torch.tensor(X_train).float().to(DEVICE)\n",
    "Ytr_t = torch.tensor(Y_train).float().to(DEVICE)\n",
    "w_t = torch.tensor(weights).float().to(DEVICE)\n",
    "\n",
    "for epoch in trange(20, desc=\"CR-PMLE Training\"):\n",
    "    perm = np.random.permutation(len(X_train))\n",
    "    for i in range(0, len(perm), 256):\n",
    "        ids = perm[i:i+256]\n",
    "        xb, yb, wb = Xtr_t[ids], Ytr_t[ids], w_t[ids]\n",
    "        opt.zero_grad()\n",
    "        pred = model_w(xb)\n",
    "        loss = (loss_fn(pred, yb).mean(1) * wb).mean()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "print(\"CR-PMLE model training complete.\")\n",
    "\n",
    "model_w.eval()\n",
    "with torch.no_grad():\n",
    "    preds_w = model_w(torch.tensor(X_test).float().to(DEVICE)).cpu().numpy()\n",
    "mse_weighted = mean_squared_error(Y_test, preds_w)\n",
    "print(f\"Weighted MSE (after correction): {mse_weighted:.6f}\")\n",
    "\n",
    "torch.save(model_w.state_dict(), \"covid_model_weighted.pth\")\n",
    "\n",
    "# -----------------------------------------------\n",
    "# FINAL COMPARISON\n",
    "# -----------------------------------------------\n",
    "print(\"\\n================= RESULTS =================\")\n",
    "print(f\"Before Correction (MLE)   MSE: {mse_baseline:.6f}\")\n",
    "print(f\"After Correction (CR-PMLE) MSE: {mse_weighted:.6f}\")\n",
    "improvement = ((mse_baseline - mse_weighted) / mse_baseline) * 100\n",
    "print(f\"Improvement in Robustness: {improvement:.2f}%\")\n",
    "print(\"===========================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9602bfd1-2261-43b5-a319-674c60a314a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python_basic]",
   "language": "python",
   "name": "conda-env-python_basic-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
